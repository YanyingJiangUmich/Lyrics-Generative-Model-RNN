{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOWg9p-xn-yU"
   },
   "source": [
    "### **Introduction**\n",
    "\n",
    "\n",
    "We are planning to build a generative model for song lyrics that involves training a machine learning algorithm to learn the patterns and structures that exist within a corpus of existing song lyrics, and then using this knowledge to generate new lyrics that are similar in style and content to the original corpus.\n",
    "\n",
    "There are a few steps I would like to follow to build a generative model for song lyrics:\n",
    "\n",
    "Gather a corpus of song lyrics from our dataset. We may also choose a specific genre or artist as a starting point to test. We may also start with english lyrics first.\n",
    "\n",
    "Preprocess the data by removing irrelevant information, tokenization, stemming and lemmatization. \n",
    "\n",
    "Train a language model: Use a deep learning algorithm like a Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) to train a language model on the preprocessed lyrics data. The model will learn the relationships between the words and phrases in the corpus and will be able to generate new lyrics based on this knowledge. \n",
    "\n",
    "Generate new lyrics: Once the model is trained, we can use it to generate new lyrics by giving it a starting prompt or seed. The model will then use its knowledge of the patterns and structures in the corpus to generate new lyrics that are similar in style and content to the original lyrics.\n",
    "\n",
    "Evaluate the results: Evaluate the generated lyrics to see how well they match the style and content of the original corpus. We may use metrics like perplexity, BLEU score, or human evaluation to assess the quality of the generated lyrics. We would like to explore if LSTM can perform better than RNN in terms of lyrics generation. \n",
    "\n",
    "Refine the model: If the generated lyrics are not of high quality, we would refine the model by adjusting the hyperparameters or training it on a larger or more diverse corpus of lyrics.\n",
    "\n",
    "We anticipate that generating high-quality song lyrics can be challenging, as there are many nuances and complexities in the language and structure of lyrics. Therefore, it's important to carefully evaluate and refine the model to ensure that it generates high-quality lyrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWFKZaChr1Hw"
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZ3fo50rsVbk",
    "outputId": "4c6681fc-7098-40f7-fc81-2966c9d1ba7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/yyk/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/yyk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/yyk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import lzma\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "colab = False\n",
    "if colab == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    file_path = os.path.join('/content/drive/MyDrive/',file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loGC5AE58CzR"
   },
   "source": [
    "### Getting the Data Ready\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVT9iMQeaCFd"
   },
   "source": [
    "#### Compile a list of top US artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "XnBza9XjtZcs"
   },
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('lyrics-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xfOO4u6guOs0",
    "outputId": "30ea2179-615c-4fbc-a774-8071e88885ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Arerê</td>\n",
       "      <td>/ivete-sangalo/arere.html</td>\n",
       "      <td>Tudo o que eu quero nessa vida,\\nToda vida, é\\...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Se Eu Não Te Amasse Tanto Assim</td>\n",
       "      <td>/ivete-sangalo/se-eu-nao-te-amasse-tanto-assim...</td>\n",
       "      <td>Meu coração\\nSem direção\\nVoando só por voar\\n...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Céu da Boca</td>\n",
       "      <td>/ivete-sangalo/chupa-toda.html</td>\n",
       "      <td>É de babaixá!\\nÉ de balacubaca!\\nÉ de babaixá!...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Quando A Chuva Passar</td>\n",
       "      <td>/ivete-sangalo/quando-a-chuva-passar.html</td>\n",
       "      <td>Quando a chuva passar\\n\\nPra quê falar\\nSe voc...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Sorte Grande</td>\n",
       "      <td>/ivete-sangalo/sorte-grande.html</td>\n",
       "      <td>A minha sorte grande foi você cair do céu\\nMin...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ALink                            SName  \\\n",
       "0  /ivete-sangalo/                            Arerê   \n",
       "1  /ivete-sangalo/  Se Eu Não Te Amasse Tanto Assim   \n",
       "2  /ivete-sangalo/                      Céu da Boca   \n",
       "3  /ivete-sangalo/            Quando A Chuva Passar   \n",
       "4  /ivete-sangalo/                     Sorte Grande   \n",
       "\n",
       "                                               SLink  \\\n",
       "0                          /ivete-sangalo/arere.html   \n",
       "1  /ivete-sangalo/se-eu-nao-te-amasse-tanto-assim...   \n",
       "2                     /ivete-sangalo/chupa-toda.html   \n",
       "3          /ivete-sangalo/quando-a-chuva-passar.html   \n",
       "4                   /ivete-sangalo/sorte-grande.html   \n",
       "\n",
       "                                               Lyric language  \n",
       "0  Tudo o que eu quero nessa vida,\\nToda vida, é\\...       pt  \n",
       "1  Meu coração\\nSem direção\\nVoando só por voar\\n...       pt  \n",
       "2  É de babaixá!\\nÉ de balacubaca!\\nÉ de babaixá!...       pt  \n",
       "3  Quando a chuva passar\\n\\nPra quê falar\\nSe voc...       pt  \n",
       "4  A minha sorte grande foi você cair do céu\\nMin...       pt  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Careless Whisper</td>\n",
       "      <td>/ivete-sangalo/careless-whisper.html</td>\n",
       "      <td>I feel so unsure\\nAs I take your hand and lead...</td>\n",
       "      <td>en</td>\n",
       "      <td>ivete sangalo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Could You Be Loved / Citação Musical do Rap: S...</td>\n",
       "      <td>/ivete-sangalo/could-you-be-loved-citacao-musi...</td>\n",
       "      <td>Don't let them fool, ya\\nOr even try to school...</td>\n",
       "      <td>en</td>\n",
       "      <td>ivete sangalo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Cruisin' (Part. Saulo)</td>\n",
       "      <td>/ivete-sangalo/cruisin-part-saulo.html</td>\n",
       "      <td>Baby, let's cruise, away from here\\nDon't be c...</td>\n",
       "      <td>en</td>\n",
       "      <td>ivete sangalo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Easy</td>\n",
       "      <td>/ivete-sangalo/easy.html</td>\n",
       "      <td>Know it sounds funny\\nBut, I just can't stand ...</td>\n",
       "      <td>en</td>\n",
       "      <td>ivete sangalo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>For Your Babies (The Voice cover)</td>\n",
       "      <td>/ivete-sangalo/for-your-babies-the-voice-cover...</td>\n",
       "      <td>You've got that look again\\nThe one I hoped I ...</td>\n",
       "      <td>en</td>\n",
       "      <td>ivete sangalo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ALink                                              SName  \\\n",
       "69   /ivete-sangalo/                                   Careless Whisper   \n",
       "86   /ivete-sangalo/  Could You Be Loved / Citação Musical do Rap: S...   \n",
       "88   /ivete-sangalo/                             Cruisin' (Part. Saulo)   \n",
       "111  /ivete-sangalo/                                               Easy   \n",
       "140  /ivete-sangalo/                  For Your Babies (The Voice cover)   \n",
       "\n",
       "                                                 SLink  \\\n",
       "69                /ivete-sangalo/careless-whisper.html   \n",
       "86   /ivete-sangalo/could-you-be-loved-citacao-musi...   \n",
       "88              /ivete-sangalo/cruisin-part-saulo.html   \n",
       "111                           /ivete-sangalo/easy.html   \n",
       "140  /ivete-sangalo/for-your-babies-the-voice-cover...   \n",
       "\n",
       "                                                 Lyric language         artist  \n",
       "69   I feel so unsure\\nAs I take your hand and lead...       en  ivete sangalo  \n",
       "86   Don't let them fool, ya\\nOr even try to school...       en  ivete sangalo  \n",
       "88   Baby, let's cruise, away from here\\nDon't be c...       en  ivete sangalo  \n",
       "111  Know it sounds funny\\nBut, I just can't stand ...       en  ivete sangalo  \n",
       "140  You've got that look again\\nThe one I hoped I ...       en  ivete sangalo  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['artist'] = df_all['ALink'].str.replace('[\\/]','')\n",
    "df_all['artist'] = df_all['artist'].str.replace('[\\-]',' ')\n",
    "df_all = df_all[df_all.language == 'en']\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aimed to compile a list of the top 50 American artists based on their song count. However, certain artists were excluded due to either not being from the United States or being a collective of multiple artists. As a result, our refined list features 32 exceptional US artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a count of unique artist names\n",
    "artist_counts = df_all['artist'].value_counts()\n",
    "top50 = artist_counts[:50]\n",
    "#filtering out non-American singers/bands \n",
    "exclusion = ['temas de filmes','matheus hardke','glee','hillsong united','elton john','bee gees','elvis costello','paul mccartney','vineyard','david bowie','the rolling stones','rod stewart','van morrison','kylie minogue','u2','the beatles','eric clapton','drake']\n",
    "US_top = top50.loc[~top50.index.isin(exclusion)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Top US Artists: 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "frank sinatra        819\n",
       "elvis presley        747\n",
       "dolly parton         723\n",
       "lil wayne            689\n",
       "chris brown          623\n",
       "guided by voices     620\n",
       "prince               564\n",
       "johnny cash          555\n",
       "bob dylan            548\n",
       "george jones         534\n",
       "neil young           515\n",
       "bruce springsteen    502\n",
       "snoop dogg           485\n",
       "eminem               484\n",
       "50 cent              466\n",
       "roy orbison          438\n",
       "ella fitzgerald      421\n",
       "taylor swift         385\n",
       "waylon jennings      383\n",
       "2pac tupac shakur    382\n",
       "bb king              371\n",
       "bon jovi             367\n",
       "george strait        365\n",
       "madonna              360\n",
       "diana ross           355\n",
       "bill monroe          351\n",
       "beach boys           332\n",
       "barry manilow        330\n",
       "alice cooper         326\n",
       "nas                  324\n",
       "ray charles          322\n",
       "beck                 320\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of Top US Artists:',len(US_top))\n",
    "US_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above list, we conducted more data-preprocessing to remove songs with featured artists, and removed text inside () and []. See Kenny Tang's notebook for more details.\n",
    "Now we import the new clean dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_lyrics_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5400</td>\n",
       "      <td>50 cent</td>\n",
       "      <td>In da Club</td>\n",
       "      <td>/50-cent/in-da-club.html</td>\n",
       "      <td>go, go, go, go\\ngo, go, go shawty\\nit's your b...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5401</td>\n",
       "      <td>50 cent</td>\n",
       "      <td>21 Questions</td>\n",
       "      <td>/50-cent/21-questions.html</td>\n",
       "      <td>new york city!\\nyou are now rapping...with 50 ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5402</td>\n",
       "      <td>50 cent</td>\n",
       "      <td>P.I.M.P.</td>\n",
       "      <td>/50-cent/p-i-m-p.html</td>\n",
       "      <td>i don't know what you heard about me\\nbut a b*...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5403</td>\n",
       "      <td>50 cent</td>\n",
       "      <td>Many Men (Wish Death)</td>\n",
       "      <td>/50-cent/many-men-wish-death.html</td>\n",
       "      <td>man we gotta go get something to eat man\\ni'm ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5404</td>\n",
       "      <td>50 cent</td>\n",
       "      <td>Candy Shop</td>\n",
       "      <td>/50-cent/candy-shop.html</td>\n",
       "      <td>yeah...\\nuh huh\\nso seductive\\ni'll take you t...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    ALink                  SName  \\\n",
       "0        5400  50 cent             In da Club   \n",
       "1        5401  50 cent           21 Questions   \n",
       "2        5402  50 cent               P.I.M.P.   \n",
       "3        5403  50 cent  Many Men (Wish Death)   \n",
       "4        5404  50 cent             Candy Shop   \n",
       "\n",
       "                               SLink  \\\n",
       "0           /50-cent/in-da-club.html   \n",
       "1         /50-cent/21-questions.html   \n",
       "2              /50-cent/p-i-m-p.html   \n",
       "3  /50-cent/many-men-wish-death.html   \n",
       "4           /50-cent/candy-shop.html   \n",
       "\n",
       "                                               Lyric language  features  \n",
       "0  go, go, go, go\\ngo, go, go shawty\\nit's your b...       en     False  \n",
       "1  new york city!\\nyou are now rapping...with 50 ...       en     False  \n",
       "2  i don't know what you heard about me\\nbut a b*...       en     False  \n",
       "3  man we gotta go get something to eat man\\ni'm ...       en     False  \n",
       "4  yeah...\\nuh huh\\nso seductive\\ni'll take you t...       en     False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61P3vOnluSUm",
    "outputId": "9becc582-7d58-45d2-f660-2eda73a43155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ddGdTaNT0FRw",
    "outputId": "73f31795-1e8e-41b2-a99f-9d4d7041aafe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>songname</th>\n",
       "      <th>songlink</th>\n",
       "      <th>lyric</th>\n",
       "      <th>language</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>In da Club</td>\n",
       "      <td>/50-cent/in-da-club.html</td>\n",
       "      <td>go, go, go, go\\ngo, go, go shawty\\nit's your b...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>21 Questions</td>\n",
       "      <td>/50-cent/21-questions.html</td>\n",
       "      <td>new york city!\\nyou are now rapping...with 50 ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>P.I.M.P.</td>\n",
       "      <td>/50-cent/p-i-m-p.html</td>\n",
       "      <td>i don't know what you heard about me\\nbut a b*...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>Many Men (Wish Death)</td>\n",
       "      <td>/50-cent/many-men-wish-death.html</td>\n",
       "      <td>man we gotta go get something to eat man\\ni'm ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>Candy Shop</td>\n",
       "      <td>/50-cent/candy-shop.html</td>\n",
       "      <td>yeah...\\nuh huh\\nso seductive\\ni'll take you t...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist               songname                           songlink  \\\n",
       "0  50 cent             In da Club           /50-cent/in-da-club.html   \n",
       "1  50 cent           21 Questions         /50-cent/21-questions.html   \n",
       "2  50 cent               P.I.M.P.              /50-cent/p-i-m-p.html   \n",
       "3  50 cent  Many Men (Wish Death)  /50-cent/many-men-wish-death.html   \n",
       "4  50 cent             Candy Shop           /50-cent/candy-shop.html   \n",
       "\n",
       "                                               lyric language  features  \n",
       "0  go, go, go, go\\ngo, go, go shawty\\nit's your b...       en     False  \n",
       "1  new york city!\\nyou are now rapping...with 50 ...       en     False  \n",
       "2  i don't know what you heard about me\\nbut a b*...       en     False  \n",
       "3  man we gotta go get something to eat man\\ni'm ...       en     False  \n",
       "4  yeah...\\nuh huh\\nso seductive\\ni'll take you t...       en     False  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = [\"artist\", \"songname\", \"songlink\", \"lyric\", \"language\",\"features\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "id": "PewrdWrOuV8o",
    "outputId": "8e35c763-a5f7-4110-806e-99f6355ccd72"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>songname</th>\n",
       "      <th>songlink</th>\n",
       "      <th>lyric</th>\n",
       "      <th>language</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>In da Club</td>\n",
       "      <td>/50-cent/in-da-club.html</td>\n",
       "      <td>go, go, go, go\\ngo, go, go shawty\\nit's your b...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>21 Questions</td>\n",
       "      <td>/50-cent/21-questions.html</td>\n",
       "      <td>new york city!\\nyou are now rapping...with 50 ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>P.I.M.P.</td>\n",
       "      <td>/50-cent/p-i-m-p.html</td>\n",
       "      <td>i don't know what you heard about me\\nbut a b*...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>Many Men (Wish Death)</td>\n",
       "      <td>/50-cent/many-men-wish-death.html</td>\n",
       "      <td>man we gotta go get something to eat man\\ni'm ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>Candy Shop</td>\n",
       "      <td>/50-cent/candy-shop.html</td>\n",
       "      <td>yeah...\\nuh huh\\nso seductive\\ni'll take you t...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14323</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>You Oughta Be Home With Me</td>\n",
       "      <td>/barry-manilow/you-oughta-be-home-with-me.html</td>\n",
       "      <td>everybody's here, spinnin' the bottle\\neverybo...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14324</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>You're Leaving Too Soon</td>\n",
       "      <td>/barry-manilow/youre-leaving-too-soon.html</td>\n",
       "      <td>you're leavin' too soon\\nyou oughta try believ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14325</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>You're Looking Hot Tonight</td>\n",
       "      <td>/barry-manilow/youre-looking-hot-tonight.html</td>\n",
       "      <td>you're looking hot tonight\\nbarry manilow\\nby:...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14326</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>You're There</td>\n",
       "      <td>/barry-manilow/youre-there.html</td>\n",
       "      <td>our friends all use the past tense when they s...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14327</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>Young At Heart</td>\n",
       "      <td>/barry-manilow/young-at-heart.html</td>\n",
       "      <td>fairy tales can come true, it can happen to yo...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14328 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                    songname  \\\n",
       "0            50 cent                  In da Club   \n",
       "1            50 cent                21 Questions   \n",
       "2            50 cent                    P.I.M.P.   \n",
       "3            50 cent       Many Men (Wish Death)   \n",
       "4            50 cent                  Candy Shop   \n",
       "...              ...                         ...   \n",
       "14323  barry manilow  You Oughta Be Home With Me   \n",
       "14324  barry manilow     You're Leaving Too Soon   \n",
       "14325  barry manilow  You're Looking Hot Tonight   \n",
       "14326  barry manilow                You're There   \n",
       "14327  barry manilow              Young At Heart   \n",
       "\n",
       "                                             songlink  \\\n",
       "0                            /50-cent/in-da-club.html   \n",
       "1                          /50-cent/21-questions.html   \n",
       "2                               /50-cent/p-i-m-p.html   \n",
       "3                   /50-cent/many-men-wish-death.html   \n",
       "4                            /50-cent/candy-shop.html   \n",
       "...                                               ...   \n",
       "14323  /barry-manilow/you-oughta-be-home-with-me.html   \n",
       "14324      /barry-manilow/youre-leaving-too-soon.html   \n",
       "14325   /barry-manilow/youre-looking-hot-tonight.html   \n",
       "14326                 /barry-manilow/youre-there.html   \n",
       "14327              /barry-manilow/young-at-heart.html   \n",
       "\n",
       "                                                   lyric language  features  \n",
       "0      go, go, go, go\\ngo, go, go shawty\\nit's your b...       en     False  \n",
       "1      new york city!\\nyou are now rapping...with 50 ...       en     False  \n",
       "2      i don't know what you heard about me\\nbut a b*...       en     False  \n",
       "3      man we gotta go get something to eat man\\ni'm ...       en     False  \n",
       "4      yeah...\\nuh huh\\nso seductive\\ni'll take you t...       en     False  \n",
       "...                                                  ...      ...       ...  \n",
       "14323  everybody's here, spinnin' the bottle\\neverybo...       en     False  \n",
       "14324  you're leavin' too soon\\nyou oughta try believ...       en     False  \n",
       "14325  you're looking hot tonight\\nbarry manilow\\nby:...       en     False  \n",
       "14326  our friends all use the past tense when they s...       en     False  \n",
       "14327  fairy tales can come true, it can happen to yo...       en     False  \n",
       "\n",
       "[14328 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en = df[df.language == 'en']\n",
    "df_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Export the DataFrame to a pickle file\n",
    "pickle_file = \"df_en.pickle\"\n",
    "df_en.to_pickle(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRLsQtabDzLd"
   },
   "source": [
    "In some cases, stopwords may actually carry important contextual information and contribute to the overall meaning and tone of the lyrics. Removing them may result in the loss of nuance and the creation of less coherent lyrics. To generate more nuanced and complex lyrics, we may keep the stopwords.\n",
    "\n",
    "Lemmatization can also result in the loss of some information, as certain forms of a word may have different meanings and connotations. For example, \"loving\" and \"loved\" have different meanings and may be used in different contexts, so reducing both of them to \"love\" may lead to some loss of sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "msPx0RrH0CX1"
   },
   "outputs": [],
   "source": [
    "stop_word_list = stopwords.words('english')\n",
    "lemma= WordNetLemmatizer()\n",
    "def text_preprocess(sentence, stopwords_removal = True):\n",
    "    '''This function takes in a dataframe, extract and format the text in a standardized format.'''\n",
    "    sentence = str(sentence)\n",
    "    sentence = sentence.lower() # lower case\n",
    "    sentence = re.sub(r'[^a-zA-Z0-9]', r' ', sentence)   # replace these punctuation with space\n",
    "    # sentence = re.sub(r'lrb|rrb', r'', sentence)\n",
    "    tokens = sentence.split()\n",
    "    clean_text = []\n",
    "    for item in tokens:\n",
    "        if stopwords_removal == True:\n",
    "            if item not in stop_word_list:\n",
    "                clean_text.append(lemma.lemmatize(item))\n",
    "        else:\n",
    "             clean_text.append(lemma.lemmatize(item))\n",
    "    clean_text  = \" \".join(clean_text)\n",
    "\n",
    "    return clean_text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KzvisdbcBPAi",
    "outputId": "5ce5c493-dc1b-40e4-83e0-52a876378840"
   },
   "outputs": [],
   "source": [
    "df_en['cleaned_lyric'] = df_en['lyric'].apply(lambda x:text_preprocess(x,stopwords_removal = False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "id": "GbREdQxzKWc0",
    "outputId": "2901753b-1b89-462c-cf9f-ed2851030439"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>songname</th>\n",
       "      <th>songlink</th>\n",
       "      <th>lyric</th>\n",
       "      <th>language</th>\n",
       "      <th>features</th>\n",
       "      <th>cleaned_lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>In da Club</td>\n",
       "      <td>/50-cent/in-da-club.html</td>\n",
       "      <td>go, go, go, go\\ngo, go, go shawty\\nit's your b...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>go go go go go go go shawty it s your birthday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>21 Questions</td>\n",
       "      <td>/50-cent/21-questions.html</td>\n",
       "      <td>new york city!\\nyou are now rapping...with 50 ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>new york city you are now rapping with 50 cent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>P.I.M.P.</td>\n",
       "      <td>/50-cent/p-i-m-p.html</td>\n",
       "      <td>i don't know what you heard about me\\nbut a b*...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>i don t know what you heard about me but a b c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>Many Men (Wish Death)</td>\n",
       "      <td>/50-cent/many-men-wish-death.html</td>\n",
       "      <td>man we gotta go get something to eat man\\ni'm ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>man we gotta go get something to eat man i m h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>Candy Shop</td>\n",
       "      <td>/50-cent/candy-shop.html</td>\n",
       "      <td>yeah...\\nuh huh\\nso seductive\\ni'll take you t...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>yeah uh huh so seductive i ll take you to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14323</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>You Oughta Be Home With Me</td>\n",
       "      <td>/barry-manilow/you-oughta-be-home-with-me.html</td>\n",
       "      <td>everybody's here, spinnin' the bottle\\neverybo...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>everybody s here spinnin the bottle everybody ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14324</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>You're Leaving Too Soon</td>\n",
       "      <td>/barry-manilow/youre-leaving-too-soon.html</td>\n",
       "      <td>you're leavin' too soon\\nyou oughta try believ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>you re leavin too soon you oughta try believin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14325</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>You're Looking Hot Tonight</td>\n",
       "      <td>/barry-manilow/youre-looking-hot-tonight.html</td>\n",
       "      <td>you're looking hot tonight\\nbarry manilow\\nby:...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>you re looking hot tonight barry manilow by 1a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14326</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>You're There</td>\n",
       "      <td>/barry-manilow/youre-there.html</td>\n",
       "      <td>our friends all use the past tense when they s...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>our friend all use the past tense when they sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14327</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>Young At Heart</td>\n",
       "      <td>/barry-manilow/young-at-heart.html</td>\n",
       "      <td>fairy tales can come true, it can happen to yo...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>fairy tale can come true it can happen to you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14328 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                    songname  \\\n",
       "0            50 cent                  In da Club   \n",
       "1            50 cent                21 Questions   \n",
       "2            50 cent                    P.I.M.P.   \n",
       "3            50 cent       Many Men (Wish Death)   \n",
       "4            50 cent                  Candy Shop   \n",
       "...              ...                         ...   \n",
       "14323  barry manilow  You Oughta Be Home With Me   \n",
       "14324  barry manilow     You're Leaving Too Soon   \n",
       "14325  barry manilow  You're Looking Hot Tonight   \n",
       "14326  barry manilow                You're There   \n",
       "14327  barry manilow              Young At Heart   \n",
       "\n",
       "                                             songlink  \\\n",
       "0                            /50-cent/in-da-club.html   \n",
       "1                          /50-cent/21-questions.html   \n",
       "2                               /50-cent/p-i-m-p.html   \n",
       "3                   /50-cent/many-men-wish-death.html   \n",
       "4                            /50-cent/candy-shop.html   \n",
       "...                                               ...   \n",
       "14323  /barry-manilow/you-oughta-be-home-with-me.html   \n",
       "14324      /barry-manilow/youre-leaving-too-soon.html   \n",
       "14325   /barry-manilow/youre-looking-hot-tonight.html   \n",
       "14326                 /barry-manilow/youre-there.html   \n",
       "14327              /barry-manilow/young-at-heart.html   \n",
       "\n",
       "                                                   lyric language  features  \\\n",
       "0      go, go, go, go\\ngo, go, go shawty\\nit's your b...       en     False   \n",
       "1      new york city!\\nyou are now rapping...with 50 ...       en     False   \n",
       "2      i don't know what you heard about me\\nbut a b*...       en     False   \n",
       "3      man we gotta go get something to eat man\\ni'm ...       en     False   \n",
       "4      yeah...\\nuh huh\\nso seductive\\ni'll take you t...       en     False   \n",
       "...                                                  ...      ...       ...   \n",
       "14323  everybody's here, spinnin' the bottle\\neverybo...       en     False   \n",
       "14324  you're leavin' too soon\\nyou oughta try believ...       en     False   \n",
       "14325  you're looking hot tonight\\nbarry manilow\\nby:...       en     False   \n",
       "14326  our friends all use the past tense when they s...       en     False   \n",
       "14327  fairy tales can come true, it can happen to yo...       en     False   \n",
       "\n",
       "                                           cleaned_lyric  \n",
       "0      go go go go go go go shawty it s your birthday...  \n",
       "1      new york city you are now rapping with 50 cent...  \n",
       "2      i don t know what you heard about me but a b c...  \n",
       "3      man we gotta go get something to eat man i m h...  \n",
       "4      yeah uh huh so seductive i ll take you to the ...  \n",
       "...                                                  ...  \n",
       "14323  everybody s here spinnin the bottle everybody ...  \n",
       "14324  you re leavin too soon you oughta try believin...  \n",
       "14325  you re looking hot tonight barry manilow by 1a...  \n",
       "14326  our friend all use the past tense when they sp...  \n",
       "14327  fairy tale can come true it can happen to you ...  \n",
       "\n",
       "[14328 rows x 7 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "4Loe6SFkEmyY"
   },
   "outputs": [],
   "source": [
    "df_en.to_csv('NN_Test_Data/preprocessed_english_lyrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRec-zYLG8eZ"
   },
   "source": [
    "#### Filter by Artist Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "2_1xyJ-ECUqH",
    "outputId": "48b0c65c-aec3-40d7-9bbf-f0c186c806f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>songname</th>\n",
       "      <th>songlink</th>\n",
       "      <th>lyric</th>\n",
       "      <th>language</th>\n",
       "      <th>features</th>\n",
       "      <th>cleaned_lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>In da Club</td>\n",
       "      <td>/50-cent/in-da-club.html</td>\n",
       "      <td>go, go, go, go\\ngo, go, go shawty\\nit's your b...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>go go go go go go go shawty it s your birthday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>21 Questions</td>\n",
       "      <td>/50-cent/21-questions.html</td>\n",
       "      <td>new york city!\\nyou are now rapping...with 50 ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>new york city you are now rapping with 50 cent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>P.I.M.P.</td>\n",
       "      <td>/50-cent/p-i-m-p.html</td>\n",
       "      <td>i don't know what you heard about me\\nbut a b*...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>i don t know what you heard about me but a b c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>Many Men (Wish Death)</td>\n",
       "      <td>/50-cent/many-men-wish-death.html</td>\n",
       "      <td>man we gotta go get something to eat man\\ni'm ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>man we gotta go get something to eat man i m h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>Candy Shop</td>\n",
       "      <td>/50-cent/candy-shop.html</td>\n",
       "      <td>yeah...\\nuh huh\\nso seductive\\ni'll take you t...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>yeah uh huh so seductive i ll take you to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14323</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>You Oughta Be Home With Me</td>\n",
       "      <td>/barry-manilow/you-oughta-be-home-with-me.html</td>\n",
       "      <td>everybody's here, spinnin' the bottle\\neverybo...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>everybody s here spinnin the bottle everybody ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14324</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>You're Leaving Too Soon</td>\n",
       "      <td>/barry-manilow/youre-leaving-too-soon.html</td>\n",
       "      <td>you're leavin' too soon\\nyou oughta try believ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>you re leavin too soon you oughta try believin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14325</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>You're Looking Hot Tonight</td>\n",
       "      <td>/barry-manilow/youre-looking-hot-tonight.html</td>\n",
       "      <td>you're looking hot tonight\\nbarry manilow\\nby:...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>you re looking hot tonight barry manilow by 1a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14326</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>You're There</td>\n",
       "      <td>/barry-manilow/youre-there.html</td>\n",
       "      <td>our friends all use the past tense when they s...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>our friend all use the past tense when they sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14327</th>\n",
       "      <td>barry manilow</td>\n",
       "      <td>Young At Heart</td>\n",
       "      <td>/barry-manilow/young-at-heart.html</td>\n",
       "      <td>fairy tales can come true, it can happen to yo...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>fairy tale can come true it can happen to you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14328 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                    songname  \\\n",
       "0            50 cent                  In da Club   \n",
       "1            50 cent                21 Questions   \n",
       "2            50 cent                    P.I.M.P.   \n",
       "3            50 cent       Many Men (Wish Death)   \n",
       "4            50 cent                  Candy Shop   \n",
       "...              ...                         ...   \n",
       "14323  barry manilow  You Oughta Be Home With Me   \n",
       "14324  barry manilow     You're Leaving Too Soon   \n",
       "14325  barry manilow  You're Looking Hot Tonight   \n",
       "14326  barry manilow                You're There   \n",
       "14327  barry manilow              Young At Heart   \n",
       "\n",
       "                                             songlink  \\\n",
       "0                            /50-cent/in-da-club.html   \n",
       "1                          /50-cent/21-questions.html   \n",
       "2                               /50-cent/p-i-m-p.html   \n",
       "3                   /50-cent/many-men-wish-death.html   \n",
       "4                            /50-cent/candy-shop.html   \n",
       "...                                               ...   \n",
       "14323  /barry-manilow/you-oughta-be-home-with-me.html   \n",
       "14324      /barry-manilow/youre-leaving-too-soon.html   \n",
       "14325   /barry-manilow/youre-looking-hot-tonight.html   \n",
       "14326                 /barry-manilow/youre-there.html   \n",
       "14327              /barry-manilow/young-at-heart.html   \n",
       "\n",
       "                                                   lyric language  features  \\\n",
       "0      go, go, go, go\\ngo, go, go shawty\\nit's your b...       en     False   \n",
       "1      new york city!\\nyou are now rapping...with 50 ...       en     False   \n",
       "2      i don't know what you heard about me\\nbut a b*...       en     False   \n",
       "3      man we gotta go get something to eat man\\ni'm ...       en     False   \n",
       "4      yeah...\\nuh huh\\nso seductive\\ni'll take you t...       en     False   \n",
       "...                                                  ...      ...       ...   \n",
       "14323  everybody's here, spinnin' the bottle\\neverybo...       en     False   \n",
       "14324  you're leavin' too soon\\nyou oughta try believ...       en     False   \n",
       "14325  you're looking hot tonight\\nbarry manilow\\nby:...       en     False   \n",
       "14326  our friends all use the past tense when they s...       en     False   \n",
       "14327  fairy tales can come true, it can happen to yo...       en     False   \n",
       "\n",
       "                                           cleaned_lyric  \n",
       "0      go go go go go go go shawty it s your birthday...  \n",
       "1      new york city you are now rapping with 50 cent...  \n",
       "2      i don t know what you heard about me but a b c...  \n",
       "3      man we gotta go get something to eat man i m h...  \n",
       "4      yeah uh huh so seductive i ll take you to the ...  \n",
       "...                                                  ...  \n",
       "14323  everybody s here spinnin the bottle everybody ...  \n",
       "14324  you re leavin too soon you oughta try believin...  \n",
       "14325  you re looking hot tonight barry manilow by 1a...  \n",
       "14326  our friend all use the past tense when they sp...  \n",
       "14327  fairy tale can come true it can happen to you ...  \n",
       "\n",
       "[14328 rows x 7 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_en\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_R-CQrMH6pN"
   },
   "source": [
    "Although we have a cleaned version of lyrics but we would like to export a version for the orginal lyrics for the generative model as it's character-based. We would like the model to learn the patterns of the orginal lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "qivP8jrbcbVg",
    "outputId": "a34105cd-f1df-4ca2-a04e-d0e8b0b36536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# Get the top n most common names\n",
    "top_artist = US_top.index\n",
    "print(len(top_artist))\n",
    "top_artist = ['frank sinatra', 'elvis presley', 'dolly parton', 'lil wayne',\n",
    "       'chris brown', 'guided by voices', 'prince', 'johnny cash', 'bob dylan',\n",
    "       'george jones', 'neil young', 'bruce springsteen', 'snoop dogg',\n",
    "       'eminem', '50 cent', 'roy orbison', 'ella fitzgerald', 'taylor swift',\n",
    "       'waylon jennings', '2pac tupac shakur', 'bb king', 'bon jovi',\n",
    "       'george strait', 'madonna', 'diana ross', 'bill monroe', 'beach boys',\n",
    "       'barry manilow', 'alice cooper', 'nas', 'ray charles', 'beck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8WcDq_uIVFFY",
    "outputId": "66595b71-6e31-4ac5-dcf8-ff29cd3fcd99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14328\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataframe by the top artists\n",
    "data_topUS = data[data['artist'].isin(top_artist)]\n",
    "print(len(data_topUS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "OeWuniR7WU9S"
   },
   "outputs": [],
   "source": [
    "# export the 'lyric' column to a text file\n",
    "data_topUS['lyric'].to_csv('NN_Test_Data/topUS32.txt', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "GQdxMZJM2NmH"
   },
   "outputs": [],
   "source": [
    "def extract_artist(data,artist_name):\n",
    "    df_artist = data[data.artist == artist_name]\n",
    "    df_artist['lyric'].to_csv('NN_Test_Data/{}.txt'.format(artist_name),mode='w',header=False, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVafJRB63Rt9"
   },
   "source": [
    "for artist in top_artist:\n",
    "    extract_artist(data,artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The below needs to be clean up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5sHmd04pOpA"
   },
   "source": [
    "### **RNN - GRU**\n",
    "\n",
    "Recurrent Neural Networks (RNNs) can be used as a type of language model, as they are capable of predicting the probability of a sequence of words in a natural language.\n",
    "\n",
    "In an RNN-based language model, the network takes in a sequence of words as input, one word at a time, and processes each word in the context of the previous words in the sequence. This allows the model to capture the dependencies and relationships between the words in the sequence.\n",
    "\n",
    "The RNN language model consists of an input layer, an RNN layer, and an output layer. The RNN layer maintains a hidden state that is updated at each time step, and this hidden state serves as a memory that encodes the information from the previous words in the sequence. The output layer of the model predicts the probability distribution over the possible next words in the sequence.\n",
    "\n",
    "Training an RNN language model involves minimizing the cross-entropy loss between the predicted probability distribution and the actual next word in the sequence. The model can be fine-tuned using a variety of techniques, such as backpropagation through time (BPTT), which adjusts the model's parameters to minimize the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRXn00rJTApn"
   },
   "source": [
    "#### Import Processed Data and Setup Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-LsrK9yXpSfa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWI-3nbO8qtf"
   },
   "source": [
    "##### Select an artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "9edbd4ef5b504769a2f5c2ea58972062",
      "260482ae30c946fcbed93d015c6fb8c7",
      "db0a4257606244e78653718a73f94d30"
     ]
    },
    "id": "scdE0RYl7epO",
    "outputId": "ae1b66e4-d977-4152-b2bf-72b6d92c41b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edbd4ef5b504769a2f5c2ea58972062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select artist:', options=('frank sinatra', 'elvis presley', 'dolly parton', 'lil wayne',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "top_artist = ['frank sinatra', 'elvis presley', 'dolly parton', 'lil wayne',\n",
    "       'chris brown', 'guided by voices', 'prince', 'johnny cash', 'bob dylan',\n",
    "       'george jones', 'neil young', 'bruce springsteen', 'snoop dogg',\n",
    "       'eminem', '50 cent', 'roy orbison', 'ella fitzgerald', 'taylor swift',\n",
    "       'waylon jennings', '2pac tupac shakur', 'bb king', 'bon jovi',\n",
    "       'george strait', 'madonna', 'diana ross', 'bill monroe', 'beach boys',\n",
    "       'barry manilow', 'alice cooper', 'nas', 'ray charles', 'beck']\n",
    "print(len(top_artist))\n",
    "options = top_artist\n",
    "dropdown = widgets.Dropdown(options=options, value=options[0], description='Select artist:')\n",
    "display(dropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zk7MtlV68UNo",
    "outputId": "85043177-efdf-4aa6-b6da-9b42714532b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taylor swift\n"
     ]
    }
   ],
   "source": [
    "print(dropdown.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6w8Mm4WLozv",
    "outputId": "c2dfdac4-ae30-40b1-83be-15502b687a66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taylor swift\n",
      "/content/drive/MyDrive/Capstone/NN_Test_Data/taylor swift.txt\n"
     ]
    }
   ],
   "source": [
    "artist_name = dropdown.value\n",
    "print(artist_name)\n",
    "file_path = '/content/drive/MyDrive/Capstone/NN_Test_Data/{}.txt'.format(artist_name)\n",
    "print(file_path)\n",
    "#file_path_topUS = \"/content/drive/MyDrive/Capstone/NN_Test_Data/\" + \"original_topUS32.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AX45X5rGN8YG"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 16>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(vocab)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m unique characters\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m text, vocab \n\u001B[0;32m---> 16\u001B[0m text,vocab \u001B[38;5;241m=\u001B[39m create_vocab(\u001B[43mfile_path\u001B[49m)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m#### Text Vectorization\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m#Now create the tf.keras.layers.StringLookup layer:\u001B[39;00m\n\u001B[1;32m     19\u001B[0m ids_from_chars \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mStringLookup(\n\u001B[1;32m     20\u001B[0m     vocabulary\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlist\u001B[39m(vocab), mask_token\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'file_path' is not defined"
     ]
    }
   ],
   "source": [
    "def create_vocab(file_path):\n",
    "\n",
    "    # Read, then decode for py2 compat.\n",
    "    text = open(file_path, 'rb').read().decode(encoding='utf-8')\n",
    "    # length of text is the number of characters in it\n",
    "    print(f'Length of text: {len(text)} characters')\n",
    "    # Take a look at the first 200 characters in text\n",
    "    print(text[:200])\n",
    "\n",
    "    # The unique characters in the file\n",
    "    vocab = sorted(set(text))\n",
    "    print(f'{len(vocab)} unique characters')\n",
    "\n",
    "    return text, vocab \n",
    "\n",
    "text,vocab = create_vocab(file_path)\n",
    "#### Text Vectorization\n",
    "#Now create the tf.keras.layers.StringLookup layer:\n",
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)\n",
    "ids_from_chars\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))\n",
    "#the model expects sequences of 100 tokens in length\n",
    "seq_length = 100\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))\n",
    "\n",
    "\n",
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n",
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())\n",
    "#This function effectively splits each sequence in the dataset into an input sequence and a corresponding target sequence, which is a common preprocessing step in many natural language processing problems\n",
    "\n",
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "#### Build The GRU Model\n",
    "\n",
    "#Main Parameters:\n",
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) #The input layer. A trainable lookup table that will map each character-ID to a vector with embedding_dim dimensions;\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True) # A type of RNN with size units=rnn_units\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x\n",
    "\n",
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())\n",
    "\n",
    "\n",
    "#### Train the GRU Model\n",
    "#https://stackoverflow.com/questions/53515547/check-perplexity-of-a-language-model\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def perplexity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    The perplexity metric. Why isn't this part of Keras yet?!\n",
    "    https://stackoverflow.com/questions/41881308/how-to-calculate-perplexity-of-rnn-in-tensorflow\n",
    "    https://github.com/keras-team/keras/issues/8267\n",
    "    \"\"\"\n",
    "    cross_entropy = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    perplexity = K.exp(cross_entropy)\n",
    "    return perplexity\n",
    "\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)\n",
    "tf.exp(example_batch_mean_loss).numpy()\n",
    "# Define the model architecture and compile it, define the metrics\n",
    "# model.compile(optimizer='adam', loss=loss)\n",
    "model.compile(optimizer='adam', loss=loss, metrics=[perplexity]) # YJ: added custom metrics\n",
    "# Define the path to the checkpoint directory\n",
    "checkpoint_dir = '/content/drive/MyDrive/Capstone/training_checkpoints' #save to our google drive\n",
    "\n",
    "# Create the checkpoint directory if it doesn't exist\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_model_{epoch}\")\n",
    "\n",
    "# Define a callback to save the model during training\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True,\n",
    "    # save_best_only=True,\n",
    "    # monitor='val_loss',\n",
    "    # # mode='min',\n",
    "    # save_freq=5,\n",
    "    # overwrite=True\n",
    ")                                #yj: added params for what to save\n",
    "EPOCHS = 10\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n",
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states\n",
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)\n",
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['oh baby'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)\n",
    "\n",
    "# Save the output to a text file\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "filename = os.path.join(\"/content/drive/MyDrive/Capstone/MySavedModel/\", f\"{artist_name}_output_{timestamp}.txt\")\n",
    "with open(filename, 'w') as file:\n",
    "    file.write(result[0].numpy().decode('utf-8'))\n",
    "#### Save the model\n",
    "# saved_model_path = '/content/drive/MyDrive/Capstone/MySavedModel/'\n",
    "# tf.saved_model.save(one_step_model, saved_model_path)\n",
    "# one_step_reloaded = tf.saved_model.load(saved_model_path)\n",
    "\n",
    "saved_model_path = os.path.join(\"/content/drive/MyDrive/Capstone/MySavedModel\", artist_name)\n",
    "tf.saved_model.save(one_step_model, saved_model_path)\n",
    "\n",
    "# Load the saved model\n",
    "# one_step_reloaded = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2MlnIw-zESW",
    "outputId": "3c2d5257-5692-4b37-f5d4-c50880e260f3"
   },
   "outputs": [],
   "source": [
    "#Lyrics generation \n",
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['oh baby'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char) \n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)\n",
    "\n",
    "# Save the output to a text file\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "filename = os.path.join(saved_model_path, f\"{artist_name}_output_{timestamp}.txt\")\n",
    "with open(filename, 'w') as file:\n",
    "    file.write(result[0].numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Function for One-Step Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "top_artist = ['frank sinatra', 'elvis presley', 'dolly parton', 'lil wayne',\n",
    "              'chris brown', 'guided by voices', 'prince', 'johnny cash', 'bob dylan',\n",
    "              'george jones', 'neil young', 'bruce springsteen', 'snoop dogg',\n",
    "              'eminem', '50 cent', 'roy orbison', 'ella fitzgerald', 'taylor swift',\n",
    "              'waylon jennings', '2pac tupac shakur', 'bb king', 'bon jovi',\n",
    "              'george strait', 'madonna', 'diana ross', 'bill monroe', 'beach boys',\n",
    "              'barry manilow', 'alice cooper', 'nas', 'ray charles', 'beck']\n",
    "for artist in top_artist:\n",
    "    one_step_training(artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def one_step_training(artist_name):\n",
    "    #file_path = '/content/drive/MyDrive/Capstone/NN_Test_Data/{}.txt'.format(artist_name)\n",
    "    file_path = 'Capstone/NN_Test_Data/{}.txt'.format(artist_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1moggtHwABY_"
   },
   "source": [
    "### Evaluate the GRU Model \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Zz1R2bVAAO2"
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/53515547/check-perplexity-of-a-language-model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def perplexity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    The perplexity metric. Why isn't this part of Keras yet?!\n",
    "    https://stackoverflow.com/questions/41881308/how-to-calculate-perplexity-of-rnn-in-tensorflow\n",
    "    https://github.com/keras-team/keras/issues/8267\n",
    "    \"\"\"\n",
    "    cross_entropy = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    perplexity = K.exp(cross_entropy)\n",
    "    return perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1mWctLJBfn7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eA1BHc1P33F"
   },
   "source": [
    "### LSTM \n",
    "LSTM (Long Short-Term Memory) and RNN (Recurrent Neural Network) are both types of neural networks that can be used for text generation. However, there are some key differences between the two approaches.\n",
    "\n",
    "RNNs are a type of neural network that are designed to work with sequential data, such as text. They process input data one token at a time and maintain a \"memory\" of the previous tokens they have seen. This makes RNNs well-suited for text generation tasks where the context of the previous tokens is important for predicting the next token.\n",
    "\n",
    "LSTMs are a type of RNN that are specifically designed to address the \"vanishing gradient\" problem that can occur in standard RNNs. This problem can cause the RNN to have difficulty learning long-term dependencies in the data, which can be important for text generation tasks. LSTMs use a more complex architecture that includes a \"memory cell\" and several \"gates\" that control the flow of information into and out of the cell. This allows LSTMs to better capture long-term dependencies in the data and can lead to improved performance for text generation tasks.\n",
    "\n",
    "Overall, while both RNNs and LSTMs can be used for text generation, LSTMs are generally considered to be more powerful and effective for this task due to their ability to capture long-term dependencies in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEzofZVqk_b_"
   },
   "source": [
    "#### Build the LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3Cfknaoc6xc"
   },
   "source": [
    "Now let's modify the above model using a LSTM layer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wmm-7SYYlEGJ"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYyWwCPvnFX1"
   },
   "source": [
    "Modifications made: \n",
    "\n",
    "1. Replaced tf.keras.layers.GRU with tf.keras.layers.LSTM\n",
    "2. The LSTM layer returns two states - state_h and state_c - corresponding to the hidden state and cell state respectively. We need to unpack these states from the output of the LSTM layer so we modified the if return_state block to return both state_h and state_c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlGbhIUGlQ5m"
   },
   "outputs": [],
   "source": [
    "class MyLSTMModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) \n",
    "    self.lstm = tf.keras.layers.LSTM(rnn_units,\n",
    "                                     return_sequences=True,\n",
    "                                     return_state=True) \n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.lstm.get_initial_state(x)\n",
    "    x, state_h, state_c = self.lstm(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, [state_h, state_c]\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aaZR8MDTXlgb"
   },
   "outputs": [],
   "source": [
    "# What to tune\n",
    "# vocab_size and embedding_dim can be tuned for the embedding\n",
    "# rnn_units can be tuned to make the model have more or less parameters, watch out for overfit\n",
    "# loss function may change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPz_-nAylQ5n"
   },
   "outputs": [],
   "source": [
    "LSTM_model = MyLSTMModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCpcVLYjlQ5n"
   },
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = LSTM_model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HggGxDZFlQ5n"
   },
   "outputs": [],
   "source": [
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POYbdV3TlQ5n"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bykOeZjylQ5n"
   },
   "outputs": [],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wpwmv2wmlQ5n"
   },
   "outputs": [],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdOqd1BEP6c8"
   },
   "outputs": [],
   "source": [
    "# # concatenate all the lyrics into a single string\n",
    "# # all_britney = ' '.join(britney['cleaned_lyric'])\n",
    "\n",
    "# # create a tokenizer and fit it on the concatenated string\n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(britney['cleaned_lyric'])\n",
    "# word_index = tokenizer.word_index\n",
    "# sequences = tokenizer.texts_to_sequences(britney['cleaned_lyric'])\n",
    "\n",
    "# # Create a sequence dataset\n",
    "# max_sequence_length = 50\n",
    "# sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_length, padding='pre'))\n",
    "\n",
    "# input_sequences = sequences[:, :-1]\n",
    "# output_sequences = sequences[:, -1]\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((input_sequences, output_sequences))\n",
    "# dataset = dataset.shuffle(len(input_sequences)).batch(64)\n",
    "\n",
    "# # Build and train the model\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Embedding(len(word_index)+1, 128, input_length=max_sequence_length-1),\n",
    "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
    "#     tf.keras.layers.Dense(len(word_index)+1, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(dataset, epochs=50)\n",
    "\n",
    "# # Generate lyrics\n",
    "# seed_text = \"I wanna hold your hand\"\n",
    "# next_words = 100\n",
    "\n",
    "# for _ in range(next_words):\n",
    "#     sequence = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "#     sequence = pad_sequences([sequence], maxlen=max_sequence_length-1, padding='pre')\n",
    "#     predicted = model.predict(sequence)[0]\n",
    "#     predicted_word_index = np.argmax(predicted)\n",
    "#     output_word = ''\n",
    "#     for word, index in word_index.items():\n",
    "#         if index == predicted_word_index:\n",
    "#             output_word = word\n",
    "#             break\n",
    "#     seed_text += ' ' + output_word\n",
    "\n",
    "# print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QaFAo4UAnWXs"
   },
   "source": [
    "#### Train the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5A5HP3wou1t"
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1hMTA_wou1u"
   },
   "outputs": [],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6PPN25Vou1u"
   },
   "outputs": [],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcqX_Opzou1u"
   },
   "outputs": [],
   "source": [
    "LSTM_model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BsQUQmFkou1v"
   },
   "outputs": [],
   "source": [
    "# # Directory where the checkpoints will be saved\n",
    "# checkpoint_dir = './training_checkpoints'\n",
    "# # Name of the checkpoint files\n",
    "# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "# checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=checkpoint_prefix,\n",
    "#     save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7xW1CECou1v"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aoz2_Em1ou1v"
   },
   "outputs": [],
   "source": [
    "history = LSTM_model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OzLnUdfou1v"
   },
   "outputs": [],
   "source": [
    "# inference\n",
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMYEePHpou1v"
   },
   "outputs": [],
   "source": [
    "one_step_model = OneStep(LSTM_model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQwMraynou1v"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['oh baby'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGF1Nbs-i1kw"
   },
   "source": [
    "In the above model we first load and preprocess the lyrics data using Pandas. We then use the Tokenizer class to tokenize the lyrics data and create a sequence dataset using TensorFlow's sequence dataset functionality.\n",
    "\n",
    "Next, we build a model architecture using TensorFlow's Keras API, which consists of an embedding layer, two bidirectional LSTM layers, a dropout layer, and a dense layer with a softmax activation function. We train the model on the sequence dataset for 50 epochs.\n",
    "\n",
    "Finally, we use the trained model to generate new lyrics by starting with a seed sequence and iteratively predicting the next token in the sequence using the model's predict() method. We repeat this process for a specified number of output words and convert the sequence of predicted tokens back into text using the Tokenizer's reverse mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCXT3nStqg0C"
   },
   "source": [
    "### Ensemble Model\n",
    "\n",
    "Steps to ensemble multiple models for multiple artists:\n",
    "1. Train individual models for each artist using above LSTM model. \n",
    "2. After training, save the individual models.\n",
    "3. Load the saved models and create an ensemble model that takes in an artist's name as input and outputs a sequence of words.\n",
    "4. Use the ensemble model to generate lyrics for the specified artist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "raNu-3aDNODu"
   },
   "outputs": [],
   "source": [
    "artist_list = ['frank sinatra', 'elvis presley', 'dolly parton', 'matheus hardke',\n",
    "       'lil wayne', 'glee', 'hillsong united', 'elton john', 'temas de filmes',\n",
    "       'chris brown']\n",
    "print(artist_list)\n",
    "print(len(artist_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xf98tKU7q9qj"
   },
   "outputs": [],
   "source": [
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cihB81__rx_B"
   },
   "outputs": [],
   "source": [
    "print(latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUTlVO9P8Sfm"
   },
   "outputs": [],
   "source": [
    "# Load the model from the latest checkpoint file\n",
    "model_1 = tf.keras.models.load_model(latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cko7TbJM8bm0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "260482ae30c946fcbed93d015c6fb8c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9edbd4ef5b504769a2f5c2ea58972062": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "frank sinatra",
       "elvis presley",
       "dolly parton",
       "lil wayne",
       "chris brown",
       "guided by voices",
       "prince",
       "johnny cash",
       "bob dylan",
       "george jones",
       "neil young",
       "bruce springsteen",
       "snoop dogg",
       "eminem",
       "50 cent",
       "roy orbison",
       "ella fitzgerald",
       "taylor swift",
       "waylon jennings",
       "2pac tupac shakur",
       "bb king",
       "bon jovi",
       "george strait",
       "madonna",
       "diana ross",
       "bill monroe",
       "beach boys",
       "barry manilow",
       "alice cooper",
       "nas",
       "ray charles",
       "beck"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Select artist:",
      "description_tooltip": null,
      "disabled": false,
      "index": 17,
      "layout": "IPY_MODEL_260482ae30c946fcbed93d015c6fb8c7",
      "style": "IPY_MODEL_db0a4257606244e78653718a73f94d30"
     }
    },
    "db0a4257606244e78653718a73f94d30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
